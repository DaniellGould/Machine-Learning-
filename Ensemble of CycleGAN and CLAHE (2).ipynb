{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Download Libraries**","metadata":{}},{"cell_type":"code","source":"!pip install git+https://www.github.com/keras-team/keras-contrib.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install h5py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Import Libraries**","metadata":{}},{"cell_type":"code","source":"from keras import backend as K\nfrom keras.layers.core import Activation\nfrom keras.utils.generic_utils import get_custom_objects","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom random import random\nfrom numpy import load\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy import asarray\nfrom numpy.random import randint\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.initializers import RandomNormal\nfrom keras.models import Model\nfrom keras import Input\nfrom keras.layers import Conv2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Activation\nfrom keras.layers import Concatenate\nfrom keras.losses import KLDivergence\nfrom keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\nfrom matplotlib import pyplot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from os import listdir\nfrom numpy import asarray\nfrom numpy import vstack\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom numpy import savez_compressed\nfrom numpy import load\nimport matplotlib.pyplot as plt \nimport cv2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Load X-ray Images**","metadata":{}},{"cell_type":"code","source":"# load all images in a directory into memory\ndef load_images(path, size=(256, 256)):\n    image_list = list()\n    # enumerate filenames in directory, assume all are images\n    for filename in listdir(path):\n        # load and resize the image\n        pixels = load_img(path + filename, target_size=size)\n        # convert to numpy array\n        pixels = img_to_array(pixels)\n        # store\n        image_list.append(pixels)\n    return asarray(image_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Augmentation I: Contrast Limiting Histogram Equalization to Control Different Brightness over X-ray images**","metadata":{}},{"cell_type":"code","source":"def clahe(img): \n    clahe = cv2.createCLAHE(clipLimit=1.8, tileGridSize=(8,8))\n    for i in range(len(img)):\n        grayimg = cv2.cvtColor(img[i].astype('uint8'), cv2.COLOR_BGR2GRAY)\n        grayimg = clahe.apply(grayimg)\n        img[i] = cv2.cvtColor(grayimg, cv2.COLOR_GRAY2BGR)\n    return img\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load normal X-ray images\npath_normal = '../input/lungs-disease-dataset-4-types/Lung Disease Dataset/train/Normal/'\ndata_normal = load_images(path_normal)\nprint('Successfully Loaded normal X-ray imageset: ', data_normal.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load X-ray images of patients with Bacterial Pneumonia\npath_tub = '../input/lungs-disease-dataset-4-types/Lung Disease Dataset/train/Bacterial Pneumonia/'\ndata_tub = load_images(path_tub)\nprint('Successfully Loaded X-ray images of tuberculosis patients: ', data_tub.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_normal_val = '../input/lungs-disease-dataset-4-types/Lung Disease Dataset/val/Normal/'\ndata_normal_val = load_images(path_normal_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_tub_val = '../input/lungs-disease-dataset-4-types/Lung Disease Dataset/val/Bacterial Pneumonia/'\ndata_tub_val = load_images(path_tub_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_normal_val_aug = clahe(data_normal_val)\ndata_tub_val_aug = clahe(data_tub_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_normal_aug = clahe(data_normal)\ndata_tub_aug = clahe(data_tub)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Save X-ray Imageset**","metadata":{}},{"cell_type":"code","source":"filename = 'x_ray.npz'\nsavez_compressed(filename, data_normal, data_tub)\nprint('Successfully Saved dataset: ', filename)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = 'x_ray_aug.npz'\nsavez_compressed(filename, data_normal_aug, data_tub_aug)\nprint('Successfully Saved dataset: ', filename)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = 'x_ray_aug_val.npz'\nsavez_compressed(filename, data_normal_val_aug, data_tub_val_aug)\nprint('Successfully Saved dataset: ', filename)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = 'x_ray_val.npz'\nsavez_compressed(filename, data_normal_val, data_tub_val)\nprint('Successfully Saved dataset: ', filename)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load and plot the prepared dataset\n# load the dataset\ndata = load(filename)\nimage_normal, image_tub = data['arr_0'], data['arr_1']\n# plot source images\nplt.figure(figsize = (10, 10))\nplt.imshow(image_tub[1].astype('uint8'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_tub_aug = clahe(image_tub)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot source images\nplt.figure(figsize = (10, 10))\nplt.imshow(image_tub_aug[1].astype('uint8'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Augmentation II: CycleGAN to Generate Contrasting Samples**","metadata":{}},{"cell_type":"code","source":"def define_discriminator(image_shape):\n    # weight initialization\n    init = RandomNormal(stddev=0.02)\n    # source image input\n    in_image = Input(shape=image_shape)\n    # C64\n    d = Conv2D(32, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n    d = LeakyReLU(alpha=0.3)(d)\n    # C128\n    d = Conv2D(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = InstanceNormalization(axis=-1)(d)\n    d = LeakyReLU(alpha=0.3)(d)\n    # C256\n    d = Conv2D(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = InstanceNormalization(axis=-1)(d)\n    d = LeakyReLU(alpha=0.3)(d)\n    # C512\n    d = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = InstanceNormalization(axis=-1)(d)\n    d = LeakyReLU(alpha=0.3)(d)\n    # second last output layer\n    d = Conv2D(256, (3,3), padding='same', kernel_initializer=init)(d)\n    d = InstanceNormalization(axis=-1)(d)\n    d = Activation('gelu')(d)\n    # patch output\n    patch_out = Conv2D(1, (3,3), padding='same', kernel_initializer=init)(d)\n    # define model\n    model = Model(in_image, patch_out)\n    # compile model\n    model.compile(loss='mse', optimizer=Adam(lr=0.0001, beta_1=0.5), loss_weights=[0.5])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generator a resnet block\ndef resnet_block(n_filters, input_layer):\n    # weight initialization\n    init = RandomNormal(stddev=0.02)\n    # first layer convolutional layer\n    g = Conv2D(n_filters, (2,2), padding='same', kernel_initializer=init)(input_layer)\n    g = InstanceNormalization(axis=-1)(g)\n    g = Activation('swish')(g)\n    # second convolutional layer\n    g = Conv2D(n_filters, (2,2), padding='same', kernel_initializer=init)(g)\n    g = InstanceNormalization(axis=-1)(g)\n    # concatenate merge channel-wise with input layer\n    g = Concatenate()([g, input_layer])\n    return g","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the standalone generator model\ndef define_generator(image_shape, n_resnet=6):\n    # weight initialization\n    init = RandomNormal(stddev=0.02)\n    # image input\n    in_image = Input(shape=image_shape)\n    # c7s1-64\n    conv_64 = Conv2D(64, (7,7), padding='same', kernel_initializer=init)(in_image)\n    conv_64 = InstanceNormalization(axis=-1)(conv_64)\n    conv_64 = Activation('swish')(conv_64)\n    # d128\n    conv_128 = Conv2D(128, (2,2), strides=(2,2), padding='valid', kernel_initializer=init)(conv_64)\n    conv_128 = InstanceNormalization(axis=-1)(conv_128)\n    conv_128 = Activation('swish')(conv_128)\n    # d256\n    conv_256 = Conv2D(256, (2,2), strides=(2,2), padding='valid', kernel_initializer=init)(conv_128)\n    conv_256 = InstanceNormalization(axis=-1)(conv_256)\n    conv_256 = Activation('swish')(conv_256)\n    # u128\n    for _ in range(n_resnet):\n        conv_256 = resnet_block(256, conv_256)\n    dconv_128 = Conv2DTranspose(128, (2,2), strides=(2,2), padding='valid', kernel_initializer=init)(conv_256)\n    uconv_128 = Concatenate()([conv_128, dconv_128])\n    uconv_128 = InstanceNormalization(axis=-1)(uconv_128)\n    uconv_128 = Activation('swish')(uconv_128)\n    # u64\n    dconv_64 = Conv2DTranspose(64, (2,2), strides=(2,2), padding='valid', kernel_initializer=init)(uconv_128)\n    uconv_64 = Concatenate()([conv_64, dconv_64])\n    uconv_64 = InstanceNormalization(axis=-1)(uconv_64)\n    uconv_64 = Activation('swish')(uconv_64)\n    # c7s1-3\n    uconv_64 = Conv2D(3, (7,7), padding='same', kernel_initializer=init)(uconv_64)\n    uconv_64 = InstanceNormalization(axis=-1)(uconv_64)\n    out_image = Activation('tanh')(uconv_64)\n    # define model\n    model = Model(in_image, out_image)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define a composite model for updating generators by adversarial and cycle loss\ndef define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n    # ensure the model we're updating is trainable\n    g_model_1.trainable = True\n    # mark discriminator as not trainable\n    d_model.trainable = False\n    # mark other generator model as not trainable\n    g_model_2.trainable = False\n    # discriminator element\n    input_gen = Input(shape=image_shape)\n    gen1_out = g_model_1(input_gen)\n    output_d = d_model(gen1_out)\n    # identity element\n    input_id = Input(shape=image_shape)\n    output_id = g_model_1(input_id)\n    # forward cycle\n    output_f = g_model_2(gen1_out)\n    # backward cycle\n    gen2_out = g_model_2(input_id)\n    output_b = g_model_1(gen2_out)\n    \n    # define model graph\n    model = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n    # define optimization algorithm configuration\n    opt = Adam(lr=0.001, beta_1=0.5)\n    # compile model with weighting of least squares loss and L1 loss\n    model.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10, 5], optimizer=opt)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load and prepare training images\ndef load_real_samples(filename):\n    # load the dataset\n    data = load(filename)\n    # unpack arrays\n    X1, X2 = data['arr_0'], data['arr_1']\n    # scale from [0,255] to [-1,1]\n    X1 = (X1 - 127.5) / 127.5\n    X2 = (X2 - 127.5) / 127.5\n    return [X1, X2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select a batch of random samples, returns images and target\ndef generate_real_samples(dataset, n_samples, patch_shape):\n    # choose random instances\n    ix = randint(0, dataset.shape[0], n_samples)\n    # retrieve selected images\n    X = dataset[ix]\n    # generate 'real' class labels (1)\n    y = ones((n_samples, patch_shape, patch_shape, 1))\n    return X, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate a batch of images, returns images and targets\ndef generate_fake_samples(g_model, dataset, patch_shape):\n    # generate fake instance\n    X = g_model.predict(dataset)\n    # create 'fake' class labels (0)\n    y = zeros((len(X), patch_shape, patch_shape, 1))\n    return X, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save the generator models to file\ndef save_models(step, g_model_AtoB, g_model_BtoA):\n    filename1 = 'g_model_AtoB_%06d.h5' % (step+1)\n    g_model_AtoB.save(filename1)\n    filename2 = 'g_model_BtoA_%06d.h5' % (step+1)\n    g_model_BtoA.save(filename2)\n    print('>Saved: %s and %s' % (filename1, filename2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# update image pool for fake images\ndef update_image_pool(pool, images, max_size=50):\n    selected = list()\n    for image in images:\n        if len(pool) < max_size:\n            # stock the pool\n            pool.append(image)\n            selected.append(image)\n        elif random() < 0.5:\n            # use image, but don't add it to the pool\n            selected.append(image)\n        else:\n            # replace an existing image and use replaced image\n            ix = randint(0, len(pool))\n            selected.append(pool[ix])\n            pool[ix] = image\n    return asarray(selected)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate samples and save as a plot and save the model\ndef summarize_performance(step, g_model, trainX, name, n_samples=5):\n    # select a sample of input images\n    X_in, _ = generate_real_samples(trainX, n_samples, 0)\n    # generate translated images\n    X_out, _ = generate_fake_samples(g_model, X_in, 0)\n    # scale all pixels from [-1,1] to [0,1]\n    X_in = (X_in + 1) / 2.0\n    X_out = (X_out + 1) / 2.0\n    # plot real images\n    for i in range(n_samples):\n        pyplot.subplot(2, n_samples, 1 + i)\n        pyplot.axis('off')\n        pyplot.imshow(X_in[i])\n    # plot translated image\n    for i in range(n_samples):\n        pyplot.subplot(2, n_samples, 1 + n_samples + i)\n        pyplot.axis('off')\n        pyplot.imshow(X_out[i])\n    # save plot to file\n    filename1 = '%s_generated_plot_%06d.png'\n    pyplot.savefig(filename1)\n    pyplot.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset):\n    # define properties of the training run\n    n_epochs, n_batch, = 30, 1\n    # determine the output square shape of the discriminator\n    n_patch = d_model_A.output_shape[1]\n    # unpack dataset\n    trainA, trainB = dataset\n    # prepare image pool for fakes\n    poolA, poolB = list(), list()\n    # Make lists for storing previous generated images. \n    prev_x_fake_atob, prev_x_fake_btoa = list(), list()\n    # the number of batches per training epoch\n    bat_per_epo = int(len(trainA) / n_batch)\n    # calculate the number of training iterations\n    n_steps = bat_per_epo * n_epochs\n    # manually enumerate epochs\n    for i in range(n_steps):\n        # select a batch of real samples\n        X_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n        X_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n        # generate a batch of fake samples\n        X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n        X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n        # update fakes from pool\n        X_fakeA = update_image_pool(poolA, X_fakeA)\n        X_fakeB = update_image_pool(poolB, X_fakeB)\n        # update generator B->A via adversarial and cycle loss\n        g_loss2, _, _, _, _  = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n        # update discriminator for A -> [real/fake]\n        dA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n        dA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n        # update generator A->B via adversarial and cycle loss\n        g_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n        # update discriminator for B -> [real/fake]\n        dB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n        dB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n        if(i > 0) :\n            d_model_A.train_on_batch(prev_x_fake_btoa, y_fakeA)\n            d_model_B.train_on_batch(prev_x_fake_atob, y_fakeB) \n        prev_x_fake_atob = X_fakeB \n        prev_x_fake_btoa = X_fakeA\n        # summarize performance\n        print('>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))\n        # evaluate the model performance every so often\n        if (i+1) % (bat_per_epo * 1) == 0:\n            # plot A->B translation\n            summarize_performance(i, g_model_AtoB, trainA, 'AtoB')\n        if (i+1) % (bat_per_epo * 5) == 0:\n            # save the models\n            save_models(i, g_model_AtoB, g_model_BtoA)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# load image data\ndataset = load_real_samples('../input/xraydata/x_ray (4).npz')\nprint('Loaded', dataset[0].shape, dataset[1].shape)\n# define input shape based on the loaded dataset\nimage_shape = dataset[0].shape[1:]\n# generator: A -> B\ng_model_AtoB = define_generator(image_shape)\n# generator: B -> A\ng_model_BtoA = define_generator(image_shape)\n# discriminator: A -> [real/fake]\nd_model_A = define_discriminator(image_shape)\n# discriminator: B -> [real/fake]\nd_model_B = define_discriminator(image_shape)\n# composite: A -> B -> [real/fake, A]\nc_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n# composite: B -> A -> [real/fake, B]\nc_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)\n# train models\ntrain(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Evaluate with Pre-trained Models**","metadata":{}},{"cell_type":"code","source":"from keras.models import load_model\nfrom numpy import expand_dims\nimport numpy as np ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.resnet import ResNet50 \nfrom keras.models import Model \nfrom keras.layers import Dense \nfrom keras.layers import Flatten, Dropout\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(filename, size=(256,256)):\n    # load and resize the image\n    pixels = load_img(filename, target_size=size)\n    # convert to numpy array\n    pixels = img_to_array(pixels)\n    # transform in a sample\n    pixels = expand_dims(pixels, 0)\n    # scale from [0,255] to [-1,1]\n    pixels = (pixels - 127.5) / 127.5\n    return pixels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the image\nimage_src = load_image('../input/lungs-disease-dataset-4-types/Lung Disease Dataset/test/Normal/0105.jpeg')\n# load the model\n# translate image\nimage_tar = nb_aug_generator.predict(image_src)\n# scale from [-1,1] to [0,1]\nimage_tar = (image_tar + 1) / 2.0\n# plot the translated image\npyplot.imshow(image_tar[0])\npyplot.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_real_samples(filename):\n    # load the dataset\n    data = load(filename)\n    # unpack arrays\n    X1, X2 = data['arr_0'], data['arr_1']\n    # scale from [0,255] to [-1,1]\n    X1 = (X1 - 127.5) / 127.5\n    X2 = (X2 - 127.5) / 127.5\n    return [X1, X2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Load Validation Dataset**","metadata":{}},{"cell_type":"code","source":"norm_data, bac_data = load_real_samples('../input/xrayaugval/x_ray_aug_val.npz')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Load Cyclic Generators**","metadata":{}},{"cell_type":"code","source":"cust = {'InstanceNormalization': InstanceNormalization}\nnb_aug_generator = load_model('../input/normtobac-aug/NormtoBac_aug.h5', cust)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cust = {'InstanceNormalization': InstanceNormalization}\nbn_aug_generator = load_model('../input/bactonorm-aug/BactoNorm_aug.h5', cust)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def select_sample(dataset, n_samples):\n    # choose random instances\n    ix = randint(0, dataset.shape[0], n_samples)\n    # retrieve selected images\n    X = dataset[ix]\n    return X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Translate the negative to positive samples, and vice versa**","metadata":{}},{"cell_type":"code","source":"selected_norm = select_sample(norm_data, 30)\nnorm_to_bac = nb_aug_generator.predict(selected_norm) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_bac = select_sample(bac_data, 30)\nbac_to_norm = bn_aug_generator.predict(selected_bac)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Concatenate the validation imageset with the translated images to finalize augmentation**","metadata":{}},{"cell_type":"code","source":"bac_data_p = np.concatenate([bac_data, norm_to_bac], axis=0)\nprint('Before Adding Generated Samples: ' , bac_data.shape) \nprint('After Adding Generated Samples: ' , bac_data_p.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"norm_data_p = np.concatenate([norm_data, bac_to_norm], axis=0)\nprint('Before Adding Generated Samples: ' , norm_data.shape) \nprint('After Adding Generated Samples: ' , norm_data_p.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training set \nX = np.concatenate([bac_data, norm_data], axis=0)\ny = np.concatenate([ones(bac_data.shape[0]), zeros(norm_data.shape[0])], axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_p = np.concatenate([bac_data_p, norm_data_p], axis=0)\ny_p = np.concatenate([ones(bac_data_p.shape[0]), zeros(norm_data_p.shape[0])], axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scale(dataset):\n    for i in range(len(dataset)): \n        dataset[i] = (dataset[i] + 1) / 2.0\n    return dataset ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = scale(X) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_p = scale(X_p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_p, y_p, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ResNet50(include_top=False, input_shape=(256, 256, 3), weights=\"imagenet\") \nmodel.trainable = False\nflat1 = Flatten()(model.layers[-1].output) \nclass1 = Dropout(0.1)(flat1)\nclass1 = Dense(1024, activation='relu')(class1)\nclass1 = Dropout(0.1)(class1)\noutput = Dense(1, activation='sigmoid')(class1)\nmodel = Model(inputs=model.inputs, outputs=output)\nmodel_p = Model(inputs=model.inputs, outputs=output)\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer = Adam(learning_rate=0.007), metrics=['Accuracy'])\nmodel_p.compile(loss='binary_crossentropy', optimizer = Adam(learning_rate=0.007), metrics=['Accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model_p.fit(X_train, y_train, epochs=45, batch_size=50, shuffle=True, validation_data=(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_p.save('CLAHE+CycleGAN+ResNet_30.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save('CLAHE+CycleGAN+Resnet_30.npy',history.history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"control_history=np.load('../input/resnet-history/Resnet.npy',allow_pickle='TRUE').item()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"experimental_val_history=np.load('../input/clahe-cycleganresnet1415/clahe_cycleGanResNet_14_15.npy',allow_pickle='TRUE').item()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"experimental_wc_history = np.load('../input/cycleganresnet/CycleGANResnet.npy', allow_pickle='TRUE').item()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"experimental_val_history_30 = np.load('./CLAHE+CycleGAN+Resnet_30.npy', allow_pickle='TRUE').item()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(12,8))\nplt.plot(control_history['loss'])\nplt.plot(experimental_val_history['loss'])\nplt.plot(experimental_wc_history['loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('epochs')\nplt.legend(['ResNet50', 'CLAHE+CycleGAN+ResNet50', 'CycleGAN+ResNet50'], loc='lower right', fontsize=14)\nplt.show()\nfig.savefig('Model_Loss.jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(12,8))\nplt.plot(control_history['Accuracy'])\nplt.plot(experimental_val_history['Accuracy'])\nplt.plot(experimental_wc_history['Accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('epochs')\nplt.legend(['ResNet50', 'CLAHE+CycleGAN+ResNet50', 'CycleGAN+ResNet50'], loc='lower right', fontsize=14)\nplt.show()\nfig.savefig('Model_Loss.jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}